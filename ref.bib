@inproceedings{GULP,
 author = {Boix-Adsera, Enric and Lawrence, Hannah and Stepaniants, George and Rigollet, Philippe},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {7115--7127},
 publisher = {Curran Associates, Inc.},
 title = {{GULP}: {A} prediction-based metric between representations},
 volume = {35},
 year = {2022}
}

@misc{GULPalt,
      title={GULP: a prediction-based metric between representations}, 
      author={Enric Boix-Adsera and Hannah Lawrence and George Stepaniants and Philippe Rigollet},
      year={2022},
      eprint={2210.06545},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2210.06545}, 
}

@article{aronszajn1950theory,
  title={Theory of reproducing kernels},
  author={Aronszajn, Nachman},
  journal={Transactions of the American Mathematical Society},
  volume={68},
  number={3},
  pages={337--404},
  year={1950}
}

@book{steinwart2008support,
  title={Support {V}ector {M}achines},
  author={Steinwart, Ingo and Christmann, Andreas},
  year={2008},
  publisher={Springer Science \& Business Media}
}

@book{berlinet2011reproducing,
  title={Reproducing kernel Hilbert spaces in Probability and Statistics},
  author={Berlinet, Alain and Thomas-Agnan, Christine},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@book{reed1980methods,
  title={Methods of Modern Mathematical Physics: Functional Analysis},
  author={Reed, Michael and Simon, Barry},
  volume={1},
  year={1980},
  publisher={Gulf Professional Publishing}
}

@article{sriperumbudur2022approximate,
  title={Approximate kernel {PCA}: Computational versus statistical trade-off},
  author={Sriperumbudur, Bharath K and Sterge, Nicholas},
  journal={The Annals of Statistics},
  volume={50},
  number={5},
  pages={2713--2736},
  year={2022},
  publisher={Institute of Mathematical Statistics}
}

@book{paulsen2016introduction,
  title={An Introduction to the Theory of Reproducing Kernel Hilbert Spaces},
  author={Paulsen, Vern I and Raghupathi, Mrinal},
  volume={152},
  year={2016},
  publisher={Cambridge university press}
}

@inproceedings{kornblith2019similarity,
  title={Similarity of neural network representations revisited},
  author={Kornblith, Simon and Norouzi, Mohammad and Lee, Honglak and Hinton, Geoffrey},
  booktitle={International Conference on Machine Learning},
  pages={3519--3529},
  year={2019},
  organization={PMLR}
}

@article{kuss2003geometry,
  title={The geometry of kernel canonical correlation analysis},
  year={2003},
  author={M.Kuss and T. Graepel},
  publisher={Max Planck Institute for Biological Cybernetics}
}

@article{vinod1976canonical,
  title={Canonical ridge and econometrics of joint production},
  author={Vinod, Hrishikesh D},
  journal={Journal of Econometrics},
  volume={4},
  number={2},
  pages={147--166},
  year={1976},
  publisher={Elsevier}
}

@article{cristianini2001kernel,
  title={On kernel-target alignment},
  author={Cristianini, Nello and Shawe-Taylor, John and Elisseeff, Andre and Kandola, Jaz},
  journal={Advances in Neural Information Processing Systems},
  volume={14},
  year={2001}
}

@article{laakso2000content,
  title={Content and cluster analysis: Assessing representational similarity in neural systems},
  author={Laakso, Aarre and Cottrell, Garrison},
  journal={Philosophical psychology},
  volume={13},
  number={1},
  pages={47--76},
  year={2000},
  publisher={Taylor \& Francis}
}

@article{li2015convergent,
  title={Convergent learning: Do different neural networks learn the same representations?},
  author={Li, Yixuan and Yosinski, Jason and Clune, Jeff and Lipson, Hod and Hopcroft, John},
  journal={arXiv preprint arXiv:1511.07543},
  year={2015}
}

@article{morcos2018insights,
  title={Insights on representational similarity in neural networks with canonical correlation},
  author={Morcos, Ari and Raghu, Maithra and Bengio, Samy},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{wang2018towards,
  title={Towards understanding learning representations: To what extent do different neural networks learn the same representation},
  author={Wang, Liwei and Hu, Lunjia and Gu, Jiayuan and Hu, Zhiqiang and Wu, Yue and He, Kun and Hopcroft, John},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@article{bengio2013representation,
  title={Representation learning: A review and new perspectives},
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={35},
  number={8},
  pages={1798--1828},
  year={2013},
  publisher={IEEE}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={Nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@article{maurer2016benefit,
  title={The benefit of multitask representation learning},
  author={Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={81},
  pages={1--32},
  year={2016}
}

@inproceedings{caruana2006empirical,
  title={An empirical comparison of supervised learning algorithms},
  author={Caruana, Rich and Niculescu-Mizil, Alexandru},
  booktitle={Proceedings of the 23rd International Conference on Machine Learning},
  pages={161--168},
  year={2006}
}

@article{fernandez2014we,
  title={Do we need hundreds of classifiers to solve real world classification problems?},
  author={Fern{\'a}ndez-Delgado, Manuel and Cernadas, Eva and Barro, Sen{\'e}n and Amorim, Dinani},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={3133--3181},
  year={2014},
  publisher={JMLR. org}
}

@inproceedings{pfahringer2000meta,
  title={Meta-Learning by Landmarking Various Learning Algorithms.},
  author={Pfahringer, Bernhard and Bensusan, Hilan and Giraud-Carrier, Christophe G},
  booktitle={International Conference on Machine Learning},
  pages={743--750},
  year={2000},
  
}

@book{burnham1998practical,
  title={Practical use of the Information-Theoretic Approach},
  author={Burnham, Kenneth P and Anderson, David R and Burnham, Kenneth P and Anderson, David R},
  year={1998},
  publisher={Springer}
}

@article{spiegelhalter2002bayesian,
  title={Bayesian measures of model complexity and fit},
  author={Spiegelhalter, David J and Best, Nicola G and Carlin, Bradley P and Van Der Linde, Angelika},
  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
  volume={64},
  number={4},
  pages={583--639},
  year={2002},
  publisher={Wiley Online Library}
}

@article{deng2012mnist,
  title={The {MNIST} database of handwritten digit images for machine learning research [best of the web]},
  author={Deng, Li},
  journal={IEEE Signal Processing Magazine},
  volume={29},
  number={6},
  pages={141--142},
  year={2012},
  publisher={IEEE}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  journal={Advances in Neural Information Processing Systems},
  volume={25},
  year={2012}
}

@misc{imagenet-object-localization-challenge,
    author = {Addison Howard and Eunbyung Park and Wendy Kan},
    title = {ImageNet Object Localization Challenge},
    year = {2018},
    howpublished = {\url{https://kaggle.com/competitions/imagenet-object-localization-challenge}},
    note = {Kaggle}
}

@inproceedings{he2015delving,
  title={Delving deep into rectifiers: Surpassing human-level performance on imagenet classification},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1026--1034},
  year={2015}
}

@misc{pytorch,
  author = {PyTorch},
  title = {Models and pre-trained weights},
  howpublished = {\url{https://pytorch.org/vision/stable/models.html#classification}},
  year = {2024},
  note = {Accessed: 2024-10-17}
}

@article{lin2017distributed,
  title={Distributed learning with regularized least squares},
  author={Lin, Shao-Bo and Guo, Xin and Zhou, Ding-Xuan},
  journal={Journal of Machine Learning Research},
  volume={18},
  number={92},
  pages={1--31},
  year={2017}
}

@article{pfeiffer2021stability,
  title={On the stability of the area law for the entanglement entropy of the Landau Hamiltonian},
  author={Pfeiffer, Paul},
  journal={arXiv preprint arXiv:2102.07287},
  year={2021}
}

@article{bauer2007regularization,
  title={On regularization algorithms in learning theory},
  author={Bauer, Frank and Pereverzev, Sergei and Rosasco, Lorenzo},
  journal={Journal of complexity},
  volume={23},
  number={1},
  pages={52--72},
  year={2007},
  publisher={Elsevier}
}

@article{hagrass2024spectral,
  title={Spectral regularized kernel two-sample tests},
  author={Hagrass, Omar and Sriperumbudur, Bharath and Li, Bing},
  journal={The Annals of Statistics},
  volume={52},
  number={3},
  pages={1076--1101},
  year={2024},
  publisher={Institute of Mathematical Statistics}
}

@article{SpecAlgGerfo2008,
    author = {Gerfo, L. Lo and Rosasco, L. and Odone, F. and Vito, E. De and Verri, A.},
    title = {Spectral Algorithms for Supervised Learning},
    journal = {Neural Computation},
    volume = {20},
    number = {7},
    pages = {1873-1897},
    year = {2008},
    month = {07},
    abstract = {We discuss how a large class of regularization methods, collectively known as spectral regularization and originally designed for solving ill-posed inverse problems, gives rise to regularized learning algorithms. All of these algorithms are consistent kernel methods that can be easily implemented. The intuition behind their derivation is that the same principle allowing for the numerical stabilization of a matrix inversion problem is crucial to avoid overfitting. The various methods have a common derivation but different computational and theoretical properties. We describe examples of such algorithms, analyze their classification performance on several data sets and discuss their applicability to real-world problems.},
    issn = {0899-7667},
    doi = {10.1162/neco.2008.05-07-517},
    url = {https://doi.org/10.1162/neco.2008.05-07-517},
    eprint = {https://direct.mit.edu/neco/article-pdf/20/7/1873/817354/neco.2008.05-07-517.pdf},
}



@book{schattennormbook,
  title={Norm ideals of completely continuous operators},
  author={Schatten, Robert},
  volume={27},
  year={2013},
  publisher={Springer-Verlag}
}